Prototypical Netwoks on the Omniglot dataset

Приложен ноутбук с обучением+выводами, а модели загрузить на гитхаб проблематично было даже с LFS
Так что снова ссылкой на гг диск(тут доступны модели): https://drive.google.com/drive/folders/1u_fh4Mwv09jnCrZOoxSXVi3N6BsSEZA8?usp=sharing
Логирование сделали двойное - доступно как в папке results, так и на вандиби
ссылка на отчет вандиби по protonet-omniglot https://wandb.ai/mikisevam-/protonet-omniglot?nw=nwusermikisevam
ссылка на отчет вандиби по simclr-cifar - https://wandb.ai/mikisevam-/simclr-cifar10?nw=nwusermikisevam

Состав команды:
Микишева Мария гр. Б03-213с
Берёзкин Фёдор гр. Б03-212и

Выполненные задачи

1. Реализация и обучение модели SimCLR на CIFAR-10 (self-supervised)
— включает SimCLRModel, ProjectionHead, NT-Xent Loss, обучение, сохранение весов
— Микишева М.

 2. Обучение классификатора на замороженном SimCLR-энкодере и оценка точности
— включая реализацию классификатора, тренировку, визуализацию предсказаний, таблицу результатов
— Берёзкин Ф.

 3. Сравнение с альтернативами: обучение ResNet18 с нуля и на случайных признаках
— обучение supervised и random моделей, сравнение по метрикам, итоговая таблица и график
—  Берёзкин Ф.

 4. Реализация ProtoNet и обучение на Omniglot (few-shot learning)
— включает кастомный энкодер, 5-way 1-shot/5-shot задачи, mini-EDA по Omniglot, сравнение
— Микишева М.

 5. Визуализация результатов: графики потерь, предсказания, гистограммы
— SimCLR loss, accuracy-графики, визуализация предсказаний
— ВМЕСТЕ 

6. Автоматизация и воспроизводимость: DVC и Makefile
— пайплайны в dvc.yaml, команды в Makefile для обучения, теста, очистки
—  Берёзкин Ф.

 7. Тестирование компонентов и структуризация проекта
— модульное разделение src/, tests/, сохранение моделей, unit-тесты
— Микишева М.

 8. Итоговый README и документация проекта
— полное описание структуры, задач, выводов, инструкций
— ВМЕСТЕ


Выводы

Замороженный SimCLR-энкодер даёт выше точность, чем supervised ResNet, обученный с нуля
Обучение на случайных признаках даёт худший результат, подтверждая пользу contrastive преподобучения
| Метод       | Accuracy |
|-------------|----------|
| SimCLR      | 0.7000   |
| Scratch     | 0.5605   |
| Random      | 0.3000   |


Примечания
 В ориг статье обучение simclr на ~1000 эпох, поэтому метрики конечно выше. Но если цель задания в сравнении подходов, мы решили, что 100 эпох на simclr и 20 на классификаторы хватит, разница в метриках видна и так

- SimCLR обучался на CIFAR-10 с аугментациями, batch size = 256
- Downstream классификатор обучался поверх замороженного энкодера на 8000 примерах, проверялся на 2000
- Для визуализации сохранены предсказания CIFAR-10 (`results/predictions/`) и аналогично на Омниглоте
- Также для датасета Омниглот провели мини EDA, для Cifar не стали, тк датасет знаком
